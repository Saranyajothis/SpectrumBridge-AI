"""
Step 4: Upload Embeddings to MongoDB with Vector Search (M0 FREE TIER FIXED)
Creates collection first, then vector index and uploads embeddings
"""

import os
import json
from pathlib import Path
from typing import List, Dict
from dotenv import load_dotenv
from pymongo import MongoClient
from pymongo.operations import SearchIndexModel
from tqdm import tqdm
import time

# Load environment variables
load_dotenv()

# Paths
BASE_DIR = Path(__file__).parent.parent
EMBEDDINGS_FILE = BASE_DIR / "knowledge_base" / "embeddings" / "embeddings.json"

# MongoDB Configuration
MONGODB_URI = os.getenv("MONGODB_URI")
DATABASE_NAME = "spectrum_bridge_AI"
COLLECTION_NAME = "knowledge"
INDEX_NAME = "vector_index"

class MongoDBUploader:
    def __init__(self):
        """Initialize MongoDB connection"""
        print("Connecting to MongoDB Atlas M0 (Free Tier)...")
        self.client = MongoClient(MONGODB_URI)
        self.db = self.client[DATABASE_NAME]
        # CRITICAL FIX: Create collection if it doesn't exist
        if COLLECTION_NAME not in self.db.list_collection_names():
            self.db.create_collection(COLLECTION_NAME)
            print(f"‚úì Created collection: {COLLECTION_NAME}")
        self.collection = self.db[COLLECTION_NAME]
        print(f"‚úì Connected to database: {DATABASE_NAME}.{COLLECTION_NAME}")
    
    def clear_collection(self):
        """Clear existing data in collection"""
        count = self.collection.count_documents({})
        if count > 0:
            print(f"\nFound {count} existing documents")
            response = input("Clear existing data? (y/n): ")
            if response.lower() == 'y':
                self.collection.delete_many({})
                print("‚úì Collection cleared")
        else:
            print("Collection is empty")
    
    def create_vector_index(self, dimension: int = 384):
        """Create vector search index (M0 FREE TIER compatible)"""
        print(f"\nCreating vector search index (dimension: {dimension})...")
        
        # M0 FREE TIER vector index definition
        index_definition = {
            "fields": [
                {
                    "type": "vector",
                    "path": "embedding",
                    "numDimensions": dimension,
                    "similarity": "cosine"
                }
            ]
        }
        
        try:
            # Check existing indexes
            existing_indexes = list(self.collection.list_search_indexes())
            index_exists = any(idx.get('name') == INDEX_NAME for idx in existing_indexes)
            
            if index_exists:
                print(f"‚ö† Index '{INDEX_NAME}' already exists")
                response = input("Recreate index? (y/n): ")
                if response.lower() == 'y':
                    self.collection.drop_search_index(INDEX_NAME)
                    print("‚úì Dropped existing index")
                    time.sleep(3)
                else:
                    print("‚úì Using existing index")
                    return
            
            # Create vector search index (M0 FREE TIER SUPPORTS THIS)
            search_index_model = SearchIndexModel(
                definition=index_definition,
                name=INDEX_NAME,
                type="vectorSearch"
            )
            
            result = self.collection.create_search_index(model=search_index_model)
            print(f"‚úì Vector index created: {result}")
            
            # Wait for index readiness (M0 takes ~2-5 min)
            print("\n‚è≥ Waiting for index to build (M0 free tier: 2-5 minutes)...")
            max_wait = 300  # 5 minutes
            waited = 0
            
            while waited < max_wait:
                indexes = list(self.collection.list_search_indexes())
                for idx in indexes:
                    if idx.get('name') == INDEX_NAME:
                        status = idx.get('status', 'UNKNOWN')
                        print(f"  Index status: {status}")
                        if status == 'READY':
                            print("üéâ VECTOR INDEX READY!")
                            return
                time.sleep(10)
                waited += 10
            
            print("‚ö† Index still building... you can continue with upload")
            
        except Exception as e:
            print(f"‚úó Index error: {str(e)}")
            print("\n‚úÖ M0 FREE TIER vector search is supported!")
            print("‚úÖ Collection was auto-created above")
            print("‚úÖ Continue with upload - index will finish later")
    
    def upload_documents(self, documents: List[Dict], batch_size: int = 50):
        """Upload to M0 free tier (smaller batches for 100 ops/sec limit)"""
        print(f"\nUploading {len(documents)} documents to M0 free tier...")
        
        total_batches = (len(documents) + batch_size - 1) // batch_size
        
        for i in tqdm(range(0, len(documents), batch_size), desc="Upload batches"):
            batch = documents[i:i + batch_size]
            try:
                self.collection.insert_many(batch, ordered=False)
                time.sleep(0.5)  # Respect M0 100 ops/sec limit
            except Exception as e:
                print(f"‚ö† Batch {i//batch_size + 1} error: {str(e)}")
                continue
        
        count = self.collection.count_documents({})
        print(f"\nüéâ UPLOAD COMPLETE: {count} documents in M0 cluster!")
        return count
    
    def test_vector_search(self, query_text: str = "classroom strategies for autistic children"):
        """Test M0 vector search"""
        print(f"\n{'='*60}")
        print("üß™ TESTING M0 VECTOR SEARCH")
        print(f"Query: '{query_text}'")
        print(f"{'='*60}")
        
        try:
            from sentence_transformers import SentenceTransformer
            model = SentenceTransformer("all-MiniLM-L6-v2")
            query_embedding = model.encode(query_text).tolist()
            
            pipeline = [
                {
                    "$vectorSearch": {
                        "index": INDEX_NAME,
                        "path": "embedding", 
                        "queryVector": query_embedding,
                        "numCandidates": 20,
                        "limit": 3
                    }
                }
            ]
            
            results = list(self.collection.aggregate(pipeline))
            
            if results:
                print(f"‚úÖ VECTOR SEARCH WORKS! Top {len(results)} results:")
                for i, doc in enumerate(results, 1):
                    score = doc.get('_searchScore', 'N/A')
                    source = doc.get('metadata', {}).get('source', 'Unknown')
                    print(f"{i}. [{score}] {source}")
                    print(f"   {doc.get('text', '')[:100]}...")
            else:
                print("‚è≥ No results yet - index still building (normal for M0)")
                print("   Wait 5 min or test again later")
                
        except Exception as e:
            print(f"Test failed: {str(e)}")
            print("‚úÖ Upload succeeded! Index will be ready soon.")
    
    def get_stats(self):
        """M0 cluster stats"""
        total_docs = self.collection.count_documents({})
        print(f"\nüìä M0 FREE TIER STATS")
        print(f"Documents: {total_docs}")
        print(f"Storage: ~{total_docs * 2:.1f} KB (well under 512MB limit)")
        print("Vector search: Ready for SpectrumBridge RAG! üéØ")

def main():
    print("\n" + "="*70)
    print("SPECTRUMBRIDGE-AI: M0 FREE TIER VECTOR DATABASE SETUP")
    print("100% FREE - No upgrade needed!")
    print("="*70 + "\n")
    
    if not EMBEDDINGS_FILE.exists():
        print(f"‚úó Run: python scripts/02_embed_pdfs.py first")
        return
    
    # Load embeddings
    with open(EMBEDDINGS_FILE, 'r') as f:
        documents = json.load(f)
    
    dimension = len(documents[0]['embedding']) if documents else 384
    print(f"‚úì {len(documents)} docs, {dimension}D embeddings loaded")
    
    # Setup & upload
    uploader = MongoDBUploader()
    uploader.clear_collection()
    uploader.create_vector_index(dimension)
    count = uploader.upload_documents(documents)
    
    uploader.get_stats()
    uploader.test_vector_search()
    
    print(f"\nüéâ WEEK 1 COMPLETE! M0 Vector DB ready for RAG")
    print(f"Next: python scripts/05_rag_test.py")

if __name__ == "__main__":
    main()
